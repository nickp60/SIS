import argparse
import os
import re
import sys
import shutil
import subprocess
import itertools

import io
from contextlib import redirect_stdout

from sis import main as sis_main
from Bio import SeqIO # , SearchIO
from Bio.SeqRecord import SeqRecord


def get_args():
    parser = argparse.ArgumentParser(
        description="Use nucmer to generate coords file from a reference and"+
        "some contigs, and then scaffolds the contigs against " +
        "a reference; fill with N's")
    parser.add_argument( "reference", action="store", type=str,
                         help="reference strain")
    parser.add_argument("contigs", action="store",
                        help="path to your contigs")
    parser.add_argument("-f", "--fill", action="store_true", dest="fill",
                        default=False,
                        help="output as single file; default: %(default)s")
    parser.add_argument("-i", "--identity", action="store", dest="identity",
                        help="Percent identity for matches to be scaffolded: %(default)s,",
                        default=95)
    args = parser.parse_args()
    return(args)

def check_exes():
    program_dict = {"nucmer":None,
                    "show-coords":None,
                    "delta-filter":None}
    for program in program_dict.keys():
        if shutil.which(program) is not None:
            program_dict[program] = shutil.which(program)
        else:
            sys.stderr.write(
                str("%s must be in your PATH!  Exiting...\n") % program)
            sys.exit(1)
    return program_dict



def make_nucmer_delta_show_cmds(exes, ref, query, out_dir, prefix="out", header=True):
    """results list of cmds
    """
    # nucmer
    nucmer_cmd = "{0} {1} {2} -p {3}/{4} > {3}/nucmer.log 2>&1".format(
        exes['nucmer'], ref, query, out_dir, prefix)
    # delta-filter
    delta_filter_cmd = \
        "{0} -1 {1}/{2}.delta 2> {1}/delta-filter.log > {1}/{2}.filter".format(
            exes['delta-filter'], out_dir, prefix)
    #show-coords
    show_coords_cmd = \
        "{0} {3}{1}/{2}.filter 2> {1}/show-coords.log > {1}/{2}.coords".format(
        exes['show-coords'], out_dir, prefix,
            "" if header else "-H ")
    return [nucmer_cmd, delta_filter_cmd, show_coords_cmd]

def make_sis_cmd(exes, ref, query, out_dir, prefix="out", header=True):
    """results list of cmds
    """
    # nucmer
    nucmer_cmd = "{0} {1} {2} -p {3}/{4} > {3}/nucmer.log 2>&1".format(
        exes['nucmer'], ref, query, out_dir, prefix)
    # delta-filter
    delta_filter_cmd = \
        "{0} -1 {1}/{2}.delta 2> {1}/delta-filter.log > {1}/{2}.filter".format(
            exes['delta-filter'], out_dir, prefix)
    #show-coords
    show_coords_cmd = \
        "{0} {3}{1}/{2}.filter 2> {1}/show-coords.log > {1}/{2}.coords".format(
        exes['show-coords'], out_dir, prefix,
            "" if header else "-H ")
    return [nucmer_cmd, delta_filter_cmd, show_coords_cmd]

# Parse the coordinate file generated by nucmer or promer
def parse_coords(coords_filename) :
    info_array  = []
    coords_file = open(coords_filename)
    for line in coords_file :
        match =  re.match("\s+(\d+)\s+(\d+)\s+\|\s+(\d+)\s+(\d+)\s+\|\s+(\d+)\s+(\S+)\s+\|\s+(\S+)\s+\|(.*)\s(\S+)", line)
        #                     s1        e1           s2      e2           len1   en 2         percent
        if match and match.group(1) != "[S1]" : #ignore header line
            s1     = int(match.group(1))
            e1     = int(match.group(2))
            s2     = int(match.group(3))
            e2     = int(match.group(4))
            len1   = int(match.group(5))
            len2   = int(match.group(6))
            idy    = float(match.group(7))
            extra  = match.group(8)
            contig = match.group(9)
            info_array.append([s1,e1,s2,e2,contig, idy])
    coords_file.close()
    info_array.sort()
    return info_array

def parse_sis(sis_file) :
    scaffolds     = {}
    line_count    = 0
    this_scaff    = None
    for line in sis_file.split("\n") :
        line_count = line_count + 1
        if line.rstrip() :
            match = re.match("^>(.*?)$", line)
            if match :
                this_scaff = match.group(1).rstrip().lstrip()
                scaffolds[this_scaff] = []

            else :
                match = re.match("^(.*) ([01])$", line)
                if match :
                    scaffolds[this_scaff].append(
                        [match.group(1),int(match.group(2))])
                else :
                    sys.stderr.write("Warning: ignoring line %s:\n %s\n" % (line_count,
                                                               line))

    return scaffolds


def filter_list(lst, pos1, pos2, sim, depth="fitst"):
    """ recursively remove the longest of similar matches
    Consider [[1,   300],
              [40,  298],
              [150, 300]]
    where pos1 = 0 and pos2 = 1
    """
    # for each possible combination of the list
    #@ (0, 1), (1,2), (0,2)
    #print(depth)
    #print("old _lst")
    #print(lst)
    for i1, i2 in itertools.combinations(
            list(range(0, len(lst))), 2):
        # if the differences between starts pass our threshold, ie similar start coordinates
        #@ if abs(1 - 40) < 50: (yes)
        start , end = pos1, pos2
        # check the starts
        #print("(%d - %d)  < %d" %(lst[i1][pos1], lst[i2][pos1], sim))
        if abs(lst[i1][pos1] - lst[i2][pos1]) < sim:
            #print("yes")
            # pick longest; start with the first, and replace if a longer one is found
            #@ if abs(300-1) > abs(289 - 40) : (yes)
            if abs(lst[i1][pos2] - lst[i1][pos1]) > abs(lst[i2][pos2] - lst[i2][pos1]):
                #print("Removing:")
                #print(lst[i2])
                new_lst = [x for x in lst if x != lst[i2]]  # new list, removing the one we filtered out
            else:
                new_lst = [x for x in lst if x != lst[i1]]  # new list, removing the one we filtered out
            #print("new list:")
            #print(new_lst)
            return filter_list(new_lst, pos1, pos2, sim) # recurse
        else:
            pass
            #print ("No")
        # check the ends
        #print("(%d - %d)  < %d" %(lst[i1][pos2], lst[i2][pos2], sim))
        if abs(lst[i1][pos2] - lst[i2][pos2]) < sim:
            #print("yes")
            # pick the longer:
            #@ if abs(300-1) > abs(289 - 40) : (yes)
            if abs(lst[i1][pos2] - lst[i1][pos1]) > abs(lst[i2][pos2] - lst[i2][pos1]):
                #print("Removing:")
                #print(lst[i2])
                new_lst = [x for x in lst if x != lst[i2]]  # new list, removing the one we filtered out
            else:
                new_lst = [x for x in lst if x != lst[i1]]  # new list, removing the one we filtered out
            #print("new list:")
            #print(new_lst)
            return filter_list(new_lst, pos1, pos2, sim, depth="sencosngsg") # recurse
        else:
            pass
            #print ("No")
    if len(lst) > 1:
        #print("removing overly much")
        len_list = [abs(x[pos2] - x[pos1]) for x in lst]
        for i, l in enumerate(len_list):
            if l == max(len_list):
                return [lst[i]]
    else:
        # if no issues were found,
        #print("we done")
        return lst


def condensce_coords(coords, sim=50):
    """ simplify coords file to only include contig boundaries

    SIS does not break contigs, neither does this
    it is common to have multiple hits for each contig, indicating indels.
    Here, we filter out the internal hits, only keeping the ones neccessary
    to calculate the gaps between contigs
    First, if similar hits exist (within -/+ sim), take the longer one.
    Then, remove any internal hits

    OLD:
    [S1]     [E1]  |     [S2]     [E2]  |  [LEN 1]  [LEN 2]  |  [% IDY]  | [TAGS]
=====================================================================================
       3    65371  |    65375        1  |    65369    65375  |    99.91  | c_g NODE_1
   70474    80282  |        1     9809  |     9809     9809  |   100.00  | c_g NODE_3
   80326    85557  |     9888    15119  |     5232     5232  |    99.90  | c_g NODE_2
   80326    85557  |     1088    15119  |     5232     5232  |    99.90  | c_g NODE_2 # this line added to filer
   85444   100560  |        1    15117  |    15117    15117  |    99.99  | c_g NODE_2
  100675   105547  |    15638    20510  |     4873     4873  |   100.00  | c_g NODE_2
  100558   100751  |        1      194  |      194      194  |   100.00  | c_g NODE_4

    NEW:
    [S1]     [E1]  |     [S2]     [E2]  |  [LEN 1]  [LEN 2]  |  [% IDY]  | [TAGS]
=====================================================================================
       3    65371  |    65375        1  |    65369    65375  |    99.91  | c_g NODE_1
   70474    80282  |        1     9809  |     9809     9809  |   100.00  | c_g NODE_3
   80326    105547 |     9888    15119  |     5232     5232  |    99.90  | c_g NODE_2
  100558   100751  |        1      194  |      194      194  |   100.00  | c_g NODE_4

    NOTE:  we assume ordering at this stage, where coordinates of the
           reference in the first column [S1] are ascending
    """

    processed_contigs = []
    filtered_coords = []
    new_coords = []
    all_contigs = [line[4] for line in coords]
    duplicated_contigs = list(set([x for x in all_contigs if all_contigs.count(x) > 1]))
    #print(duplicated_contigs)
    # select best hits when overlapping
    for contig in set(all_contigs):
        contig_coords_list = [x for x in coords if x[4] == contig]
        if contig in duplicated_contigs:
            #print("filtering %s" %sim)
            # filter out  similar starts or ends:
            #print("old")
            #print(contig_coords_list)
            contig_coords_list = filter_list(contig_coords_list, 2,3, sim)
            #print("new")
            #print(contig_coords_list)
        filtered_coords.extend(contig_coords_list)
    # condesce
    #print("post filter")
    #print(filtered_coords)
    for idx, line in enumerate(filtered_coords):
        if line[4] not in processed_contigs:
            new_coords.append(line)
            processed_contigs.append(line[4])
        else: # if contig already found, change end boundary to this one
            new_coords[len(new_coords) - 1][1] = line[1]
    return new_coords


def write_scaffold(coords, contigs, thresh, sis_scaff):
    """ for each contig in coords, read through the contigs, find the rec, and write it out
    this is probably very wasteful, but oh well
    """
    scaffolded_sequences = []
    for scaff, lst in sis_scaff.items():
        for pair in lst:
            scaffolded_sequences.append(pair[0])

    new_seq = ""
    recs = []
    for idx, line in enumerate(coords):
        # skip entries not found in sis file
        if line[4] not in scaffolded_sequences:
            continue
        sys.stderr.write("processing " + " ".join([str(x) for x in line]) + "\n")
        FOUND = False
        with open(contigs, "r") as inf:
            for rec in SeqIO.parse(inf, "fasta"):
                if idx == 0:
                    recs.append(rec.id)
                if rec.id == line[4].strip():
                    FOUND = True
                    if line[2] < line[3] and line[5] >= thresh:
                        new_seq = new_seq + rec.seq
                    elif line[5] >= thresh:
                        new_seq = new_seq + rec.reverse_complement().seq
                    else:
                        pass
                    #  if not the last entry, calculate the gap length
                    if idx != len(coords) - 1:
                        gap_len = coords[idx + 1][0] - line[1]
                        new_seq = new_seq + ("N" * gap_len)
            if not FOUND:
                sys.stderr.write(
                    str("Contig %s found in coords file but " +
                        "not in contigs file seq ids: \n%s! Exiting...\n") %\
                    (line[4], "\n".join(recs)))
                sys.exit(1)
    sys.stdout.write(SeqRecord(new_seq, id="SIS_scaffolds").format("fasta"))


def main():
    args = get_args()
    exe_dict = check_exes()
    cmds = make_nucmer_delta_show_cmds(exes=exe_dict, ref=args.reference, query=args.contigs, out_dir=os.getcwd(), prefix="out", header=True)
    for cmd in cmds:
        sys.stderr.write(cmd + "\n")
        subprocess.run(cmd,
                       shell=sys.platform != "win32",
                       stdout=subprocess.PIPE,
                       stderr=subprocess.PIPE,
                       check=True)
    stdout_ = sys.stdout #Keep track of the previous value.
    f = io.StringIO()
    with redirect_stdout(f):
        sis_main(args=["sis.py", os.path.join(os.getcwd(), "out.coords")])
    sis_out = f.getvalue()
    coords = parse_coords(os.path.join(os.getcwd(), "out.coords"))
    #print("OLD")
    for l in coords:
        pass
        #print(l)
    new_coords = condensce_coords(coords, 50)
    #print("NEW")
    for l in new_coords:
        pass
        #print(l)
    scaffolds = parse_sis(sis_file=sis_out)
    write_scaffold(new_coords, args.contigs, thresh=95, sis_scaff=scaffolds)


if __name__ == "__main__":
    main()
